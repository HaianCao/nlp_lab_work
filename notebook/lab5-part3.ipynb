{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14210933,"sourceType":"datasetVersion","datasetId":9064480}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport numpy as np\nimport os\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:41:59.169682Z","iopub.execute_input":"2025-12-18T13:41:59.170451Z","iopub.status.idle":"2025-12-18T13:41:59.174237Z","shell.execute_reply.started":"2025-12-18T13:41:59.170423Z","shell.execute_reply":"2025-12-18T13:41:59.173633Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/ud-english-ewt\"\nTRAIN_FILE = os.path.join(DATA_DIR, \"en_ewt-ud-train.conllu\")\nDEV_FILE = os.path.join(DATA_DIR, \"en_ewt-ud-dev.conllu\")\nTEST_FILE = os.path.join(DATA_DIR, \"en_ewt-ud-test.conllu\")\n\nEMBED_DIM = 20000\nHIDDEN_DIM = 1024\nBATCH_SIZE = 16\nEPOCHS = 5\nLR = 0.001\n\nPAD_TOKEN = \"<PAD>\"\nUNK_TOKEN = \"<UNK>\"\nPAD_IDX = 0\nUNK_IDX = 1\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:41:59.177673Z","iopub.execute_input":"2025-12-18T13:41:59.177909Z","iopub.status.idle":"2025-12-18T13:41:59.193027Z","shell.execute_reply.started":"2025-12-18T13:41:59.177888Z","shell.execute_reply":"2025-12-18T13:41:59.192358Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"def load_conllu(file_path):\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f\"Không tìm thấy file: {file_path}\")\n\n    sentences = []\n    current_sent = []\n    \n    with open(file_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if line.startswith(\"#\"):\n                continue\n            \n            if not line:\n                if current_sent:\n                    sentences.append(current_sent)\n                    current_sent = []\n                continue\n\n            parts = line.split('\\t')\n            if len(parts) >= 4:\n                word, tag = parts[1], parts[3]\n                current_sent.append((word, tag))\n                \n    if current_sent:\n        sentences.append(current_sent)\n        \n    return sentences\n\ndef build_vocab(sentences):\n    word_set = set()\n    tag_set = set()\n    \n    for sent in sentences:\n        for word, tag in sent:\n            word_set.add(word)\n            tag_set.add(tag)\n            \n    word_to_ix = {PAD_TOKEN: PAD_IDX, UNK_TOKEN: UNK_IDX}\n    for i, w in enumerate(sorted(list(word_set)), start=2):\n        word_to_ix[w] = i\n        \n    tag_to_ix = {PAD_TOKEN: PAD_IDX}\n    for i, t in enumerate(sorted(list(tag_set)), start=1):\n        tag_to_ix[t] = i\n        \n    return word_to_ix, tag_to_ix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:41:59.194453Z","iopub.execute_input":"2025-12-18T13:41:59.194748Z","iopub.status.idle":"2025-12-18T13:41:59.214846Z","shell.execute_reply.started":"2025-12-18T13:41:59.194728Z","shell.execute_reply":"2025-12-18T13:41:59.214312Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"class POSDataset(Dataset):\n    def __init__(self, sentences, word_to_ix, tag_to_ix):\n        self.sentences = sentences\n        self.word_to_ix = word_to_ix\n        self.tag_to_ix = tag_to_ix\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self, idx):\n        sent = self.sentences[idx]\n        word_idxs = [self.word_to_ix.get(w, UNK_IDX) for w, _ in sent]\n        tag_idxs = [self.tag_to_ix.get(t, 0) for _, t in sent] \n        \n        return torch.tensor(word_idxs, dtype=torch.long), torch.tensor(tag_idxs, dtype=torch.long)\n\ndef collate_fn(batch):\n    word_seqs, tag_seqs = zip(*batch)\n    padded_words = pad_sequence(word_seqs, batch_first=True, padding_value=PAD_IDX)\n    padded_tags = pad_sequence(tag_seqs, batch_first=True, padding_value=PAD_IDX)\n    return padded_words, padded_tags","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:41:59.215971Z","iopub.execute_input":"2025-12-18T13:41:59.216207Z","iopub.status.idle":"2025-12-18T13:41:59.230255Z","shell.execute_reply.started":"2025-12-18T13:41:59.216188Z","shell.execute_reply":"2025-12-18T13:41:59.229623Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"class SimpleRNNTagger(nn.Module):\n    def __init__(self, vocab_size, tag_size, embedding_dim, hidden_dim):\n        super(SimpleRNNTagger, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=PAD_IDX)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, tag_size)\n\n    def forward(self, text):\n        # text: [batch, seq_len]\n        embedded = self.embedding(text)          # [batch, seq_len, emb_dim]\n        output, _ = self.rnn(embedded)           # [batch, seq_len, hidden_dim]\n        predictions = self.fc(output)            # [batch, seq_len, tag_size]\n        return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:41:59.230973Z","iopub.execute_input":"2025-12-18T13:41:59.231218Z","iopub.status.idle":"2025-12-18T13:41:59.248733Z","shell.execute_reply.started":"2025-12-18T13:41:59.231189Z","shell.execute_reply":"2025-12-18T13:41:59.248069Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"def calculate_accuracy(preds, targets, ignore_idx):\n    preds = preds.cpu().numpy().flatten()\n    targets = targets.cpu().numpy().flatten()\n    \n    mask = (targets != ignore_idx)\n    correct = np.sum(preds[mask] == targets[mask])\n    total = np.sum(mask)\n    \n    return correct / total if total > 0 else 0.0\n\ndef evaluate(model, dataloader, criterion):\n    model.eval()\n    total_loss = 0\n    total_acc = 0\n    \n    with torch.no_grad():\n        for words, tags in dataloader:\n            words, tags = words.to(DEVICE), tags.to(DEVICE)\n            \n            outputs = model(words)\n            loss = criterion(outputs.view(-1, outputs.shape[-1]), tags.view(-1))\n            total_loss += loss.item()\n            \n            predictions = torch.argmax(outputs, dim=-1)\n            total_acc += calculate_accuracy(predictions, tags, PAD_IDX)\n            \n    return total_loss / len(dataloader), total_acc / len(dataloader)\n\ndef predict_sentence(model, sentence, word_to_ix, tag_to_ix):\n    model.eval()\n    ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n    tokens = sentence.strip().split()\n    indices = [word_to_ix.get(w, UNK_IDX) for w in tokens]\n    \n    tensor_in = torch.tensor([indices], dtype=torch.long).to(DEVICE)\n    \n    with torch.no_grad():\n        output = model(tensor_in)\n        pred_indices = torch.argmax(output, dim=-1).squeeze(0).cpu().numpy()\n        \n    results = [(w, ix_to_tag.get(idx, \"<UNK>\")) for w, idx in zip(tokens, pred_indices)]\n    print(f\"Sentence: {sentence}\")\n    print(f\"Predicted: {results}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:41:59.250079Z","iopub.execute_input":"2025-12-18T13:41:59.250378Z","iopub.status.idle":"2025-12-18T13:41:59.267686Z","shell.execute_reply.started":"2025-12-18T13:41:59.250358Z","shell.execute_reply":"2025-12-18T13:41:59.266960Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"train_data = load_conllu(TRAIN_FILE)\ndev_data = load_conllu(DEV_FILE)\nprint(f\"Đã load: {len(train_data)} câu train, {len(dev_data)} câu dev.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:41:59.288181Z","iopub.execute_input":"2025-12-18T13:41:59.288373Z","iopub.status.idle":"2025-12-18T13:42:00.032998Z","shell.execute_reply.started":"2025-12-18T13:41:59.288354Z","shell.execute_reply":"2025-12-18T13:42:00.032354Z"}},"outputs":[{"name":"stdout","text":"Đã load: 12544 câu train, 2001 câu dev.\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"word_to_ix, tag_to_ix = build_vocab(train_data)\nprint(f\"Vocab size: {len(word_to_ix)}, Tag size: {len(tag_to_ix)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:42:00.034493Z","iopub.execute_input":"2025-12-18T13:42:00.034765Z","iopub.status.idle":"2025-12-18T13:42:00.090514Z","shell.execute_reply.started":"2025-12-18T13:42:00.034745Z","shell.execute_reply":"2025-12-18T13:42:00.089964Z"}},"outputs":[{"name":"stdout","text":"Vocab size: 20203, Tag size: 19\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"train_ds = POSDataset(train_data, word_to_ix, tag_to_ix)\ndev_ds = POSDataset(dev_data, word_to_ix, tag_to_ix)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\ndev_loader = DataLoader(dev_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:42:00.091241Z","iopub.execute_input":"2025-12-18T13:42:00.091474Z","iopub.status.idle":"2025-12-18T13:42:00.097108Z","shell.execute_reply.started":"2025-12-18T13:42:00.091454Z","shell.execute_reply":"2025-12-18T13:42:00.096527Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"model = SimpleRNNTagger(len(word_to_ix), len(tag_to_ix), EMBED_DIM, HIDDEN_DIM).to(DEVICE)\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX) \noptimizer = optim.Adam(model.parameters(), lr=LR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:42:00.097869Z","iopub.execute_input":"2025-12-18T13:42:00.098361Z","iopub.status.idle":"2025-12-18T13:42:03.700067Z","shell.execute_reply.started":"2025-12-18T13:42:00.098334Z","shell.execute_reply":"2025-12-18T13:42:03.699495Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"best_dev_acc = 0.0\n    \nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss = 0\n    train_acc_batch = 0\n    \n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", unit=\"batch\", leave=False)\n    \n    for words, tags in progress_bar:\n        words, tags = words.to(DEVICE), tags.to(DEVICE)\n        \n        optimizer.zero_grad()\n        outputs = model(words)\n        loss = criterion(outputs.view(-1, outputs.shape[-1]), tags.view(-1))\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        preds = torch.argmax(outputs, dim=-1)\n        train_acc_batch += calculate_accuracy(preds, tags, PAD_IDX)\n        \n        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_train_acc = train_acc_batch / len(train_loader)\n    \n    avg_dev_loss, avg_dev_acc = evaluate(model, dev_loader, criterion)\n    \n    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n          f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc*100:.2f}% | \"\n          f\"Dev Acc: {avg_dev_acc*100:.2f}%\")\n    \n    if avg_dev_acc > best_dev_acc:\n        best_dev_acc = avg_dev_acc\n        torch.save(model.state_dict(), \"best_model.pth\")\n        print(\"--> Saved Best Model!\")\n\nprint(f\"\\nFinal Best Dev Acc: {best_dev_acc*100:.2f}%\")\n\nprint(\"\\n--- Demo Prediction ---\")\nmodel.load_state_dict(torch.load(\"best_model.pth\", map_location=DEVICE))\npredict_sentence(model, \"The quick brown fox jumps over the lazy dog\", word_to_ix, tag_to_ix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:42:03.701411Z","iopub.execute_input":"2025-12-18T13:42:03.701656Z","iopub.status.idle":"2025-12-18T13:47:39.566649Z","shell.execute_reply.started":"2025-12-18T13:42:03.701634Z","shell.execute_reply":"2025-12-18T13:47:39.565903Z"}},"outputs":[{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5 | Train Loss: 0.4328 | Train Acc: 86.15% | Dev Acc: 85.90%\n--> Saved Best Model!\n","output_type":"stream"},{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5 | Train Loss: 0.1990 | Train Acc: 92.51% | Dev Acc: 85.66%\n","output_type":"stream"},{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5 | Train Loss: 0.1697 | Train Acc: 93.33% | Dev Acc: 85.70%\n","output_type":"stream"},{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5 | Train Loss: 0.1622 | Train Acc: 93.45% | Dev Acc: 86.23%\n--> Saved Best Model!\n","output_type":"stream"},{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5 | Train Loss: 0.1582 | Train Acc: 93.64% | Dev Acc: 85.19%\n\nFinal Best Dev Acc: 86.23%\n\n--- Demo Prediction ---\nSentence: The quick brown fox jumps over the lazy dog\nPredicted: [('The', 'DET'), ('quick', 'ADJ'), ('brown', 'ADJ'), ('fox', 'NOUN'), ('jumps', 'VERB'), ('over', 'ADP'), ('the', 'DET'), ('lazy', 'ADJ'), ('dog', 'NOUN')]\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"best_model.pth\"))\n    \ntest_sent = \"I love NLP\"\npredict_sentence(model, test_sent, word_to_ix, tag_to_ix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:47:39.567580Z","iopub.execute_input":"2025-12-18T13:47:39.567808Z","iopub.status.idle":"2025-12-18T13:47:41.035476Z","shell.execute_reply.started":"2025-12-18T13:47:39.567777Z","shell.execute_reply":"2025-12-18T13:47:41.034815Z"}},"outputs":[{"name":"stdout","text":"Sentence: I love NLP\nPredicted: [('I', 'PRON'), ('love', 'VERB'), ('NLP', 'ADV')]\n","output_type":"stream"}],"execution_count":70}]}