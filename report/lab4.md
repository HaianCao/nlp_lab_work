# Lab4 - Text Classification vÃ  Sentiment Analysis

## ğŸ—ï¸ Cáº¥u trÃºc dá»± Ã¡n

```
lab_work/
â”œâ”€â”€ src/                              # Source code chÃ­nh
â”‚   â”œâ”€â”€ models/                       # CÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i
â”‚   â”‚   â”œâ”€â”€ text_classifier.py        # LogisticRegression classifier
â”‚   â”‚   â”œâ”€â”€ naive_bayes.py           # Naive Bayes model
â”‚   â”‚   â”œâ”€â”€ neural_network.py        # Neural Network model
â”‚   â”‚   â”œâ”€â”€ gbts.py                  # Gradient Boosting model
â”‚   â”‚   â””â”€â”€ model_interface.py       # Interface chung cho models
â”‚   â”œâ”€â”€ preprocessing/               # Tiá»n xá»­ lÃ½ vÄƒn báº£n
â”‚   â”‚   â”œâ”€â”€ noise_filtering.py       # Loáº¡i bá» noise (URLs, HTML tags)
â”‚   â”‚   â”œâ”€â”€ vocab_reduction.py       # Stemming, lemmatization, stopwords
â”‚   â”‚   â””â”€â”€ preprocessor_interface.py # Interface cho preprocessing
â”‚   â”œâ”€â”€ tokenizer/                   # Tokenization
â”‚   â”‚   â”œâ”€â”€ regex_tokenizer.py       # Regex-based tokenizer
â”‚   â”‚   â””â”€â”€ tokenize_interface.py    # Interface cho tokenizers
â”‚   â”œâ”€â”€ vectorize/                   # Vector hÃ³a vÄƒn báº£n
â”‚   â”‚   â”œâ”€â”€ tf_idf.py               # TF-IDF vectorizer
â”‚   â”‚   â”œâ”€â”€ glove.py                # GloVe embeddings
â”‚   â”‚   â””â”€â”€ vectorize_interface.py   # Interface cho vectorizers
â”‚   â””â”€â”€ __init__.py                 # Package exports
â”œâ”€â”€ test/                           # Test files vÃ  thá»­ nghiá»‡m
â”‚   â”œâ”€â”€ lab5_test.py               # Test cÆ¡ báº£n vá»›i scikit-learn
â”‚   â”œâ”€â”€ lab5_spark_sentiment_analysis.py # PySpark pipeline
â”‚   â””â”€â”€ lab5_model_improvement.py   # So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p
â””â”€â”€ sentiments.csv                  # Dataset
```

## ğŸš€ CÃ¡c bÆ°á»›c thá»±c hiá»‡n

### 1. XÃ¢y dá»±ng kiáº¿n trÃºc cÆ¡ báº£n
- **BÆ°á»›c 1**: Táº¡o TextClassifier vá»›i LogisticRegression lÃ m baseline
- **BÆ°á»›c 2**: Implement interfaces chung cho models, preprocessing, tokenizers, vectorizers
- **BÆ°á»›c 3**: XÃ¢y dá»±ng pipeline cÆ¡ báº£n vá»›i TF-IDF vÃ  scikit-learn

### 2. Má»Ÿ rá»™ng vá»›i PySpark
- **BÆ°á»›c 4**: Triá»ƒn khai pipeline phÃ¢n tÃ­ch cáº£m xÃºc vá»›i PySpark MLlib
- **BÆ°á»›c 5**: Sá»­ dá»¥ng Tokenizer, StopWordsRemover, HashingTF, IDF cá»§a Spark
- **BÆ°á»›c 6**: ÄÃ¡nh giÃ¡ trÃªn dataset lá»›n (5792 máº«u)

### 3. PhÃ¡t triá»ƒn preprocessing nÃ¢ng cao
- **BÆ°á»›c 7**: Implement NoiseFiltering (loáº¡i bá» URLs, HTML tags, lowercase)
- **BÆ°á»›c 8**: XÃ¢y dá»±ng VocabReduction vá»›i NLTK (stemming, lemmatization, stopwords)
- **BÆ°á»›c 9**: Táº¡o RegexTokenizer linh hoáº¡t

### 4. TÃ­ch há»£p Word Embeddings
- **BÆ°á»›c 10**: Implement GloVeVectorizer vá»›i pre-trained model glove-wiki-gigaword-50
- **BÆ°á»›c 11**: XÃ¢y dá»±ng vectorization pipeline cho embeddings
- **BÆ°á»›c 12**: TÃ­ch há»£p vá»›i gensim library

### 5. Má»Ÿ rá»™ng models
- **BÆ°á»›c 13**: ThÃªm NaiveBayesModel vá»›i GaussianNB tá»± Ä‘á»™ng
- **BÆ°á»›c 14**: Implement NeuralNetworkModel vá»›i MLPClassifier
- **BÆ°á»›c 15**: XÃ¢y dá»±ng GBTSModel vá»›i GradientBoostingClassifier

### 6. Thá»­ nghiá»‡m vÃ  so sÃ¡nh
- **BÆ°á»›c 16**: Táº¡o lab5_model_improvement.py Ä‘á»ƒ test táº¥t cáº£ combinations
- **BÆ°á»›c 17**: So sÃ¡nh hiá»‡u suáº¥t cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau

## ğŸ“‹ HÆ°á»›ng dáº«n cháº¡y chÆ°Æ¡ng trÃ¬nh

### Táº£i cÃ¡c modules cáº§n thiáº¿t
```bash
pip install -r requirements.txt
```
### Cháº¡y modules riÃªng láº» (test internal functionality)
```bash
# Test cÃ¡c vectorizers
python -m src.vectorize.glove
python -m src.vectorize.tf_idf

# Test cÃ¡c models  
python -m src.models.naive_bayes
python -m src.models.neural_network
python -m src.models.gbts

# Test preprocessing
python -m src.preprocessing.vocab_reduction
python -m src.preprocessing.noise_filtering
```

### Cháº¡y test files
```bash
# Test cÆ¡ báº£n vá»›i LogisticRegression
python test/lab5_test.py

# Test PySpark pipeline
python test/lab5_spark_sentiment_analysis.py

# So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau
python test/lab5_model_improvement.py
```

## ğŸ“Š Káº¿t quáº£ thá»­ nghiá»‡m

### 1. Baseline - LogisticRegression (lab5_test.py)
- **Dataset**: 5792 samples (test set: ~1159 samples)  
- **Vectorizer**: TfidfVectorizer (scikit-learn)
- **Káº¿t quáº£**:
  - Accuracy: **71.53%**
  - Precision: **73.16%** 
  - Recall: **86.75%**
  - F1-Score: **79.37%**

### 2. PySpark Pipeline (lab5_spark_sentiment_analysis.py)
- **Dataset**: 5792 samples (distributed processing)
- **Pipeline**: Tokenizer â†’ StopWordsRemover â†’ HashingTF â†’ IDF â†’ LogisticRegression
- **Káº¿t quáº£**:
  - Accuracy: **73.22%**
  - Precision: **72.96%**
  - Recall: **73.22%**
  - F1-Score: **73.06%**

### 3. So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p (lab5_model_improvement.py)

| Preprocessing | Tokenizer | Vectorizer | Model | Accuracy | Precision | Recall | F1-Score |
|---------------|-----------|------------|-------|----------|-----------|--------|----------|
| NoiseFiltering | RegexTokenizer | TFIDFVectorizer | NaiveBayes | **60.22%** | **77.26%** | **52.46%** | **62.49%** |
| NoiseFiltering | RegexTokenizer | **GloVeVectorizer** | NaiveBayes | **64.11%** | **67.87%** | **81.97%** | **74.26%** |
| VocabReduction | RegexTokenizer | TFIDFVectorizer | NaiveBayes | **57.55%** | **80.00%** | **43.72%** | **56.54%** |
| VocabReduction | RegexTokenizer | **GloVeVectorizer** | NaiveBayes | **61.35%** | **68.73%** | **71.17%** | **69.93%** |

## PhÃ¢n tÃ­ch káº¿t quáº£

### Hiá»‡u suáº¥t tá»•ng thá»ƒ
1. **PySpark Pipeline** Ä‘áº¡t káº¿t quáº£ tá»‘t nháº¥t vá»›i **73.22% accuracy**
2. **Baseline LogisticRegression** cho káº¿t quáº£ á»•n Ä‘á»‹nh vá»›i **71.53% accuracy**
3. **GloVe embeddings** thÆ°á»ng cho káº¿t quáº£ tá»‘t hÆ¡n TF-IDF vá»›i NaiveBayes

### So sÃ¡nh preprocessing methods
- **NoiseFiltering**: ÄÆ¡n giáº£n nhÆ°ng hiá»‡u quáº£, giá»¯ láº¡i nhiá»u thÃ´ng tin
- **VocabReduction**: Giáº£m chiá»u dá»¯ liá»‡u nhÆ°ng cÃ³ thá»ƒ máº¥t thÃ´ng tin quan trá»ng

### So sÃ¡nh vectorization methods  
- **TF-IDF**: PhÃ¹ há»£p vá»›i NB, cho precision cao nhÆ°ng recall tháº¥p
- **GloVe**: Tá»‘t hÆ¡n cho cÃ¡c tÃ¡c vá»¥ semantic, cÃ¢n báº±ng precision-recall tá»‘t hÆ¡n

### Æ¯u Ä‘iá»ƒm GloVe embeddings
- Capture Ä‘Æ°á»£c semantic similarity giá»¯a cÃ¡c tá»«
- Pre-trained trÃªn large corpus (Wikipedia + Gigaword)
- Hoáº¡t Ä‘á»™ng tá»‘t vá»›i GaussianNB cho embedding vectors

## âš ï¸ ThÃ¡ch thá»©c vÃ  giá»›i háº¡n

### 1. Váº¥n Ä‘á» hiá»‡u suáº¥t
- **Neural Network**: Cháº¡y ráº¥t cháº­m trÃªn CPU, cáº§n GPU Ä‘á»ƒ tÄƒng tá»‘c
- **Gradient Boosting**: Memory intensive, cáº§n nhiá»u RAM cho large datasets

### 2. Interface inconsistency
- CÃ¡c models cÃ³ API khÃ¡c nhau (fit/predict vs train/classify)
- Preprocessing methods cÃ³ input/output formats khÃ¡c nhau
- Vectorizers cÃ³ method names khÃ´ng thá»‘ng nháº¥t

### 3. Giáº£i phÃ¡p Ä‘Ã£ Ã¡p dá»¥ng
- **Táº¡o interfaces chung**: ModelInterface, VectorizeInterface, PreprocessorInterface
- **Standardize API**: Táº¥t cáº£ models implement fit(), predict(), evaluate()
- **Error handling**: Tá»± Ä‘á»™ng detect vÃ  switch algorithms phÃ¹ há»£p
- **Modular design**: Dá»… dÃ ng thay Ä‘á»•i components trong pipeline

## ğŸ“š TÃ i liá»‡u tham kháº£o

1. **Scikit-learn Documentation**: Machine Learning algorithms vÃ  preprocessing
2. **PySpark MLlib Guide**: Distributed machine learning
3. **Gensim Documentation**: Word embeddings vÃ  topic modeling
4. **NLTK Documentation**: Natural language processing tools
5. **GloVe: Global Vectors for Word Representation** (Pennington et al., 2014)