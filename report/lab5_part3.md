# Lab 5: Part-of-Speech Tagging sá»­ dá»¥ng RNN

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```text
data/
â””â”€â”€ ud-english-ewt/
    â”œâ”€â”€ en_ewt-ud-train.conllu    # Dá»¯ liá»‡u huáº¥n luyá»‡n
    â”œâ”€â”€ en_ewt-ud-dev.conllu      # Dá»¯ liá»‡u validation
    â””â”€â”€ en_ewt-ud-test.conllu     # Dá»¯ liá»‡u kiá»ƒm thá»­

notebook/
â””â”€â”€ lab5-part3.ipynb
```

## ğŸ”§ CÃ¡c thÃ nh pháº§n chÃ­nh

### 1. Xá»­ lÃ½ dá»¯ liá»‡u (Data Processing)

- **CoNLL-U Parser**:

  - Äá»c Ä‘á»‹nh dáº¡ng chuáº©n CoNLL-U tá»« file raw text.
  - TÃ¡ch láº¥y cá»™t `FORM` (tá»« gá»‘c) vÃ  `UPOS` (nhÃ£n tá»« loáº¡i Universal).
  - Loáº¡i bá» cÃ¡c dÃ²ng comment (báº¯t Ä‘áº§u báº±ng `#`) vÃ  xá»­ lÃ½ cÃ¡c cÃ¢u cÃ¡ch nhau bá»Ÿi dÃ²ng trá»‘ng.

- **Vocabulary (Tá»« Ä‘iá»ƒn)**:

  - XÃ¢y dá»±ng lá»›p `Vocabulary` Ä‘á»ƒ Ã¡nh xáº¡ hai chiá»u `Token <-> Index`.
  - **Word Dictionary**: Tá»± Ä‘á»™ng thÃªm token Ä‘áº·c biá»‡t `<PAD>` (index 0) vÃ  `<UNK>` (index 1) Ä‘á»ƒ xá»­ lÃ½ cÃ¡c tá»« khÃ´ng cÃ³ trong táº­p huáº¥n luyá»‡n (Out-of-Vocabulary).
  - **Tag Dictionary**: Chá»‰ thÃªm `<PAD>` (index 0) vÃ  cÃ¡c nhÃ£n POS chuáº©n (NOUN, VERB, ADJ, ...).

- **Padding Strategy**:
  - Sá»­ dá»¥ng `pad_sequence` vá»›i tham sá»‘ `batch_first=True`.
  - CÆ¡ cháº¿ **Dynamic Padding**: Trong má»—i batch, cÃ¡c cÃ¢u Ä‘Æ°á»£c Ä‘á»‡m (pad) vá» Ä‘á»™ dÃ i cá»§a cÃ¢u dÃ i nháº¥t _trong batch Ä‘Ã³_ (thay vÃ¬ cÃ¢u dÃ i nháº¥t toÃ n bá»™ dataset). Äiá»u nÃ y giÃºp tiáº¿t kiá»‡m bá»™ nhá»› vÃ  tÄƒng tá»‘c Ä‘á»™ tÃ­nh toÃ¡n.

### 2. Kiáº¿n trÃºc MÃ´ hÃ¬nh (Model Architecture)

- **Class**: `SimpleRNNTagger`
- **Loáº¡i mÃ´ hÃ¬nh**: Vanilla RNN (RNN thuáº§n) cho bÃ i toÃ¡n Sequence Labeling.
- **Luá»“ng xá»­ lÃ½ dá»¯ liá»‡u (Forward Pass)**:
  1.  **Input**: Batch cÃ¡c chá»‰ sá»‘ tá»« (indices) cÃ³ kÃ­ch thÆ°á»›c `(Batch_Size, Seq_Len)`.
  2.  **Embedding Layer**: Chuyá»ƒn Ä‘á»•i indices thÃ nh dense vectors kÃ­ch thÆ°á»›c `(Batch_Size, Seq_Len, Embedding_Dim)`.
    3.  **RNN Layer (Vanilla RNN)**:
      - Xá»­ lÃ½ chuá»—i theo chiá»u thuáº­n (left-to-right).
      - Output dimension táº¡i má»—i bÆ°á»›c thá»i gian lÃ : `hidden_dim`.
    4.  **Linear Layer (Fully Connected)**: Chiáº¿u output cá»§a RNN vá» khÃ´ng gian nhÃ£n (`num_tags`), táº¡o ra logits Ä‘á»ƒ tÃ­nh xÃ¡c suáº¥t.

### 3. Huáº¥n luyá»‡n & ÄÃ¡nh giÃ¡ (Training & Evaluation)

- **Loss Function**: Sá»­ dá»¥ng `CrossEntropyLoss`.
  - Cáº¥u hÃ¬nh quan trá»ng: `ignore_index=PAD_IDX`. Tham sá»‘ nÃ y Ä‘áº£m báº£o mÃ´ hÃ¬nh khÃ´ng bá»‹ pháº¡t (khÃ´ng tÃ­nh loss) khi dá»± Ä‘oÃ¡n sai táº¡i cÃ¡c vá»‹ trÃ­ Ä‘á»‡m (padding), giÃºp gradient táº­p trung vÃ o cÃ¡c tá»« thá»±c.
- **Optimizer**: Sá»­ dá»¥ng `Adam` vá»›i learning rate `0.001`, cho kháº£ nÄƒng há»™i tá»¥ nhanh hÆ¡n SGD thuáº§n.
- **Metric**: Accuracy (Äá»™ chÃ­nh xÃ¡c).
  - ÄÆ°á»£c tÃ­nh toÃ¡n báº±ng thÆ° viá»‡n **Numpy** Ä‘á»ƒ tá»‘i Æ°u hiá»‡u nÄƒng.
  - Chá»‰ tÃ­nh Ä‘á»™ chÃ­nh xÃ¡c trÃªn cÃ¡c token khÃ¡c padding (masking strategy).
- **Model Selection**:
  - Theo dÃµi Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p Validation (Dev set) sau má»—i epoch.
  - Chá»‰ lÆ°u checkpoint `best_model.pth` khi `Val Accuracy` Ä‘áº¡t Ä‘á»‰nh má»›i.
- **Monitoring**: TÃ­ch há»£p thÆ° viá»‡n `tqdm` Ä‘á»ƒ hiá»ƒn thá»‹ thanh tiáº¿n trÃ¬nh (progress bar), loss, vÃ  accuracy theo thá»i gian thá»±c.

### 2. Cháº¡y huáº¥n luyá»‡n vÃ  kiá»ƒm thá»­

Luá»“ng thá»±c thi cá»§a chÆ°Æ¡ng trÃ¬nh (chi tiáº¿t):

- Load Data: Táº£i dá»¯ liá»‡u `train/dev/test` tá»« thÆ° má»¥c `data/`.
- Build Vocab: XÃ¢y dá»±ng bá»™ tá»« Ä‘iá»ƒn tá»« táº­p train (word2index, tag2index), thÃªm token Ä‘áº·c biá»‡t `<PAD>` vÃ  `<UNK>`.
- Train: Huáº¥n luyá»‡n mÃ´ hÃ¬nh qua 15 epochs, sá»­ dá»¥ng checkpoint Ä‘á»ƒ tá»± Ä‘á»™ng lÆ°u model tá»‘t nháº¥t trÃªn táº­p dev.
- Evaluate: Táº£i model tá»‘t nháº¥t (`best_model.pth`) vÃ  Ä‘Ã¡nh giÃ¡ trÃªn táº­p Test.
- Demo: Thá»±c hiá»‡n dá»± Ä‘oÃ¡n nhÃ£n cho cÃ¡c cÃ¢u vÃ­ dá»¥ tiáº¿ng Anh.

### ğŸ“Š Káº¿t quáº£ thá»­ nghiá»‡m

#### Tham sá»‘ cáº¥u hÃ¬nh (Configuration)

| Tham sá»‘       | GiÃ¡ trá»‹ | MÃ´ táº£                                       |
| ------------- | ------: | ------------------------------------------- |
| Embedding Dim |   20000 | KÃ­ch thÆ°á»›c vector biá»ƒu diá»…n tá»«              |
| Hidden Dim    |    1024 | KÃ­ch thÆ°á»›c tráº¡ng thÃ¡i áº©n cá»§a RNN           |
| Batch Size    |      16 | Sá»‘ lÆ°á»£ng máº«u dá»¯ liá»‡u trong má»™t láº§n cáº­p nháº­t |
| Epochs        |       5 | Tá»•ng sá»‘ vÃ²ng láº·p huáº¥n luyá»‡n                 |

#### Log quÃ¡ trÃ¬nh huáº¥n luyá»‡n (Máº«u)

```text
Loaded: Train(12543), Dev(2002), Test(2077)
Vocab Size: Word=16654, Tag=18

Epoch 1/5 | Train Loss: 0.4328 | Train Acc: 86.15% | Dev Acc: 85.90%
--> Saved Best Model!

Epoch 2/5 | Train Loss: 0.1990 | Train Acc: 92.51% | Dev Acc: 85.66%

Epoch 3/5 | Train Loss: 0.1697 | Train Acc: 93.33% | Dev Acc: 85.70%

Epoch 4/5 | Train Loss: 0.1622 | Train Acc: 93.45% | Dev Acc: 86.23%
--> Saved Best Model!

Epoch 5/5 | Train Loss: 0.1582 | Train Acc: 93.64% | Dev Acc: 85.19%

Final Best Dev Acc: 86.23%
```

#### Káº¿t quáº£ cuá»‘i cÃ¹ng

- Best Validation Accuracy: ~86.23%

#### Demo Prediction (vÃ­ dá»¥)

Input Sentence: "The quick brown fox jumps over the lazy dog"

Predicted Output (JSON):

```json
[
  ["The", "DET"],
  ["quick", "ADJ"],
  ["brown", "ADJ"],
  ["fox", "NOUN"],
  ["jumps", "VERB"],
  ["over", "ADP"],
  ["the", "DET"],
  ["lazy", "ADJ"],
  ["dog", "NOUN"]
]
```

Input Sentence: "I love NLP"

Predicted Output (JSON):

```json
[
  ["I", "PRON"],
  ["love", "VERB"],
  ["NLP", "ADV"]
]
```

### ğŸ’¡ PhÃ¢n tÃ­ch & ÄÃ¡nh giÃ¡

1. MÃ´ hÃ¬nh hiá»‡n táº¡i sá»­ dá»¥ng RNN thuáº§n (Vanilla RNN)

- Háº¡n cháº¿ cá»§a RNN: RNN truyá»n thá»‘ng (Vanilla RNN) gáº·p váº¥n Ä‘á» Vanishing Gradient (tiÃªu biáº¿n Ä‘áº¡o hÃ m) khiáº¿n nÃ³ khÃ³ há»c Ä‘Æ°á»£c sá»± phá»¥ thuá»™c dÃ i háº¡n. RNN cÅ©ng chá»‰ xá»­ lÃ½ theo chiá»u má»™t chiá»u (quÃ¡ khá»© -> hiá»‡n táº¡i) vÃ  thiáº¿u cÆ¡ cháº¿ cá»•ng (gates) Ä‘á»ƒ Ä‘iá»u phá»‘i thÃ´ng tin.
- Há»‡ quáº£ thá»±c tiá»…n: Vá»›i RNN thuáº§n, mÃ´ hÃ¬nh cÃ³ thá»ƒ váº«n há»c Ä‘Æ°á»£c cÃ¡c máº«u ngáº¯n háº¡n vÃ  Ä‘áº¡t káº¿t quáº£ cháº¥p nháº­n Ä‘Æ°á»£c trÃªn táº­p dá»¯ liá»‡u nÃ y, nhÆ°ng sáº½ kÃ©m hÆ¡n cÃ¡c mÃ´ hÃ¬nh cÃ³ cÆ¡ cháº¿ ghi nhá»› dÃ i háº¡n (nhÆ° LSTM/GRU) khi cáº§n xá»­ lÃ½ phá»¥ thuá»™c xa.

2. Xá»­ lÃ½ tá»« chÆ°a biáº¿t (OOV - Out of Vocabulary)

- Trong thá»±c táº¿, táº­p Test luÃ´n chá»©a nhá»¯ng tá»« chÆ°a tá»«ng xuáº¥t hiá»‡n trong táº­p Train.
- Giáº£i phÃ¡p: sá»­ dá»¥ng token `<UNK>` (Unknown) giÃºp há»‡ thá»‘ng khÃ´ng bá»‹ crash. MÃ´ hÃ¬nh há»c cÃ¡ch biá»ƒu diá»…n vector cho `<UNK>` dá»±a trÃªn cÃ¡c tá»« táº§n suáº¥t tháº¥p trong táº­p train, tá»« Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n há»£p lÃ½ cho tá»« láº¡ dá»±a trÃªn ngá»¯ cáº£nh (cÃ¡c tá»« xung quanh).

3. Tá»‘i Æ°u hiá»‡u nÄƒng

- Numpy Metrics: Chuyá»ƒn viá»‡c tÃ­nh toÃ¡n Accuracy tá»« Tensor (GPU) sang Numpy (CPU) giÃºp giáº£m táº£i cho GPU vÃ  táº­n dá»¥ng tá»‘c Ä‘á»™ xá»­ lÃ½ máº£ng cá»§a Numpy.
- Dynamic Padding: Thay vÃ¬ padding toÃ n bá»™ dataset theo cÃ¢u dÃ i nháº¥t (cÃ³ thá»ƒ lÃªn tá»›i 100-200 tá»«), ta chá»‰ padding theo Ä‘á»™ dÃ i lá»›n nháº¥t trong tá»«ng batch (vÃ­ dá»¥: 30-40 tá»«). Äiá»u nÃ y giÃºp giáº£m Ä‘Ã¡ng ká»ƒ lÆ°á»£ng tÃ­nh toÃ¡n vÃ´ Ã­ch trÃªn cÃ¡c token `<PAD>`.

### âš ï¸ KhÃ³ khÄƒn vÃ  Giáº£i phÃ¡p

1. Váº¥n Ä‘á» Padding vÃ  Loss Function

- Váº¥n Ä‘á»: CÃ¡c cÃ¢u ngáº¯n Ä‘Æ°á»£c Ä‘iá»n thÃªm token `<PAD>` (index 0). Náº¿u tÃ­nh toÃ¡n Loss trÃªn cáº£ cÃ¡c token nÃ y, mÃ´ hÃ¬nh sáº½ bá»‹ nhiá»…u vÃ¬ pháº£i há»c cÃ¡ch dá»± Ä‘oÃ¡n nhÃ£n cho `<PAD>`, lÃ m giáº£m Ä‘á»™ chÃ­nh xÃ¡c trÃªn cÃ¡c tá»« tháº­t.
- Giáº£i phÃ¡p: Sá»­ dá»¥ng tham sá»‘ `ignore_index=PAD_IDX` trong `CrossEntropyLoss`. PyTorch sáº½ tá»± Ä‘á»™ng bá» qua cÃ¡c vá»‹ trÃ­ cÃ³ nhÃ£n lÃ  0 khi tÃ­nh gradient, giÃºp mÃ´ hÃ¬nh chá»‰ táº­p trung há»c cÃ¡c tá»« cÃ³ nghÄ©a.

2. Hiá»‡n tÆ°á»£ng Overfitting

- Váº¥n Ä‘á»: Vá»›i kÃ­ch thÆ°á»›c Embedding (100) vÃ  Hidden Dim (256), mÃ´ hÃ¬nh cÃ³ sá»‘ lÆ°á»£ng tham sá»‘ khÃ¡ lá»›n so vá»›i lÆ°á»£ng dá»¯ liá»‡u train (~12k cÃ¢u), dáº«n Ä‘áº¿n viá»‡c mÃ´ hÃ¬nh "há»c váº¹t" (Acc trÃªn Train ráº¥t cao nhÆ°ng trÃªn Dev khÃ´ng tÄƒng).
- Giáº£i phÃ¡p:
  - Ãp dá»¥ng Dropout (p=0.5) táº¡i cÃ¡c lá»›p Embedding vÃ  RNN Ä‘á»ƒ ngáº«u nhiÃªn táº¯t cÃ¡c nÆ¡-ron, buá»™c mÃ´ hÃ¬nh pháº£i há»c cÃ¡c Ä‘áº·c trÆ°ng máº¡nh máº½ hÆ¡n.
  - Sá»­ dá»¥ng cÆ¡ cháº¿ Model Checkpointing: LuÃ´n lÆ°u láº¡i phiÃªn báº£n mÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t trÃªn táº­p Dev, thay vÃ¬ láº¥y mÃ´ hÃ¬nh á»Ÿ epoch cuá»‘i cÃ¹ng (thÆ°á»ng Ä‘Ã£ bá»‹ overfit).
